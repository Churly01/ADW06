/* APARTADO 2 DEL ENUNCIADO  */
/* Create a stream from the logstash topic */

SET 'auto.offset.reset'='earliest';

/* CREATE STREAM FROM LOGSTASH  */
CREATE STREAM IF NOT EXISTS 2306_apache_raw (
	tag STRING,
	timestamp STRING,
	user_agent STRUCT<uaid STRING,
		device STRUCT<name STRING>,
		version STRING,
		original STRING,
		name STRING,
		os STRUCT<full_os STRING,
			version STRING,
			name STRING>>,
	url STRUCT<original STRING>,
	http STRUCT<response STRUCT<status_code INT, body STRUCT<bytes INT>>,
		request STRUCT<method STRING>,
		version STRING>,
	geoip STRUCT<ip STRING,
		geo STRUCT<country_name STRING,
			timezone STRING,
			country_iso_code STRING,
			location STRUCT<lon DOUBLE, lat DOUBLE>,
			continent_code STRING>,
		geo_as STRUCT<organization STRUCT<name STRING>, number INT>>)
	WITH (KAFKA_TOPIC='logstash', VALUE_FORMAT='JSON'
);

/* FILTER STREAM BY TAG  */
CREATE STREAM IF NOT EXISTS 2306_apache_filtered
	WITH (KAFKA_TOPIC='adw.2306.filtered')
	AS SELECT * FROM 2306_apache_raw
	WHERE tag = '2306'
	AND geoip IS NOT NULL;

/* CREATE CONNECTOR TO MYSQL */
CREATE SOURCE CONNECTOR IF NOT EXISTS `2306-monitor-jdbc-source` WITH (
	'connector.class'='io.confluent.connect.jdbc.JdbcSourceConnector',
	'connection.url'='jdbc:mysql://mysql:3306/kafka',
	'connection.user' = 'kafka',
	'connection.password'='kpwd23',
	'mode'='incrementing',
	'incrementing.column.name'='idrt',
	'validate.non.null'='false',
	'table.whitelist'='monitor',
	'topic.prefix'='adw.2306.',
	'transforms' = 'createKey,extractInt',
	'transforms.createKey.type' = 'org.apache.kafka.connect.transforms.ValueToKey',
	'transforms.createKey.fields' = 'idrt',
	'transforms.extractInt.type' = 'org.apache.kafka.connect.transforms.ExtractField$Key',
	'transforms.extractInt.field' = 'idrt'
);

/* CREATE STREAM FROM MySQL DATA  */
CREATE STREAM IF NOT EXISTS 2306_monitor_stream (
	idrt INT,
	timestamp STRING,
	IP STRING,
	UAID STRING,
	NV INT,
	UV STRING,
	rtreg TIMESTAMP)
	WITH (KAFKA_TOPIC='adw.2306.monitor', VALUE_FORMAT='AVRO'
);

/* Create SINK Connector. pk.mode is record_value (we take a value from a record, IP, to be PK of each value) */
CREATE SINK CONNECTOR IF NOT EXISTS `2306-geoip-jdbc-sink` WITH(
    "connector.class" = 'io.confluent.connect.jdbc.JdbcSinkConnector',
    "connection.url" = 'jdbc:mysql://mysql:3306/kafka',
    "topics" = 'adw.2306.filtered',
    "table.name.format" = 'kafka',
    "key.converter" = 'io.confluent.connect.avro.AvroConverter',
    "key.converter.schema.registry.url" = 'http://schema-registry:8081',
    "key.converter.schemas.enable" = 'true',
    "value.converter" = 'io.confluent.connect.avro.AvroConverter',
    "value.converter.schema.registry.url" = 'http://schema-registry:8081',
    "value.converter.schemas.enable" = 'true',
    "connection.user" = 'kafka',
    "connection.password" = 'kpwd23',
    "auto.create" = 'false',
    "pk.mode" = 'record_value',
    "pk.fields" = 'IP',
    "insert.mode" = 'upsert',
    "delete.enabled" = 'false',
    "tasks.max" = '1');