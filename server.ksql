/* APARTADO 2 DEL ENUNCIADO  */
/* Create a stream from the logstash topic */

SET 'auto.offset.reset'='earliest';

/* CREATE STREAM FROM LOGSTASH  */
CREATE STREAM IF NOT EXISTS 2306_apache_raw (
	tag STRING,
	timestamp STRING,
	user_agent STRUCT<uaid STRING,
		device STRUCT<name STRING>,
		version STRING,
		original STRING,
		name STRING,
		os STRUCT<`full` STRING,
			version STRING,
			name STRING>>,
	url STRUCT<original STRING>,
	http STRUCT<response STRUCT<status_code INT, body STRUCT<bytes INT>>,
		request STRUCT<method STRING>,
		version STRING>,
	geoip STRUCT<ip STRING,
		geo STRUCT<country_name STRING,
			timezone STRING,
			country_iso_code STRING,
			region_iso_code STRING,
			region_name STRING,
			city_name STRING,
			location STRUCT<lon DOUBLE, lat DOUBLE>,
			continent_code STRING,
			postal_code STRING>,
		`as` STRUCT<organization STRUCT<name STRING>, number INT>>)
	WITH (KAFKA_TOPIC='logstash', VALUE_FORMAT='JSON');

CREATE STREAM IF NOT EXISTS  2306_apache_filtered
  WITH (KAFKA_TOPIC='adw.2306.filtered', KEY_FORMAT='PROTOBUF',VALUE_FORMAT='AVRO')
AS SELECT *
FROM 2306_apache_raw
WHERE
tag='2306'
  AND timestamp IS NOT NULL
  AND user_agent->uaid IS NOT NULL
  AND user_agent->device->name IS NOT NULL
  AND user_agent->version IS NOT NULL
  AND user_agent->original IS NOT NULL
  AND user_agent->name IS NOT NULL
  AND user_agent->os->`full` IS NOT NULL
  AND user_agent->os->version IS NOT NULL
  AND user_agent->os->name IS NOT NULL
  AND url->original IS NOT NULL
  AND http->response->status_code IS NOT NULL
  AND http->response->body->bytes IS NOT NULL
  AND http->request->method IS NOT NULL
  AND http->version IS NOT NULL
  AND geoip->ip IS NOT NULL
  AND geoip->geo->country_name IS NOT NULL
  AND geoip->geo->timezone IS NOT NULL
  AND geoip->geo->country_iso_code IS NOT NULL
  AND geoip->geo->region_iso_code IS NOT NULL
  AND geoip->geo->region_name IS NOT NULL
  AND geoip->geo->city_name IS NOT NULL
  AND geoip->geo->location->lon IS NOT NULL
  AND geoip->geo->location->lat IS NOT NULL
  AND geoip->geo->continent_code IS NOT NULL
  AND geoip->geo->postal_code IS NOT NULL
  AND geoip->`as`->organization->name IS NOT NULL
  AND geoip->`as`->number IS NOT NULL;

/* MOMENTO DE ESTRUCTURAR CLAVES! Metemos las 2 claves que queremos comparar con la tabla de monitor*/
CREATE STREAM IF NOT EXISTS 2306_apache_filtered_keyed
  WITH (KAFKA_TOPIC='adw.2306.filtered.keyed', KEY_FORMAT='PROTOBUF',VALUE_FORMAT='AVRO')
  AS SELECT * FROM 2306_apache_filtered
  PARTITION BY STRUCT(IP:=geoip->ip, UAID:=user_agent->uaid);

/* CREATE CONNECTOR TO MYSQL */
CREATE SOURCE CONNECTOR IF NOT EXISTS `2306-monitor-jdbc-source` WITH (
	'connector.class'='io.confluent.connect.jdbc.JdbcSourceConnector',
	'connection.url'='jdbc:mysql://mysql:3306/kafka',
	'connection.user' = 'kafka',
	'connection.password'='kpwd23',
	'mode'='incrementing',
	'incrementing.column.name'='idrt',
	'validate.non.null'='false',
	'table.whitelist'='monitor',
	'topic.prefix'='adw.2306.',
	'transforms' = 'createKey, extractInt',	 
	'transforms.createKey.type' = 'org.apache.kafka.connect.transforms.ValueToKey',
	'transforms.createKey.fields' = 'idrt',	
	'key.converter.schemas.enable' = 'true',
	'transforms.extractInt.type' = 'org.apache.kafka.connect.transforms.ExtractField$Key',
	'transforms.extractInt.field' = 'idrt'
);

CREATE STREAM IF NOT EXISTS 2306_monitor_stream (
	idrt INT,
	IP STRING,
	UAID STRING,
	NV INT,
	UV STRING,
	rtreg TIMESTAMP)
WITH (KAFKA_TOPIC='adw.2306.monitor', VALUE_FORMAT='AVRO');


CREATE STREAM IF NOT EXISTS 2306_monitor_stream_keyed
       WITH (KAFKA_TOPIC='adw.2306.monitor.keyed', KEY_FORMAT='PROTOBUF', VALUE_FORMAT='AVRO')
       AS SELECT * FROM 2306_monitor_stream
       PARTITION BY STRUCT(IP:=ip, UAID:=uaid), NV, UV;

-- SELECT L.KEY, T.NV, L.V FROM 2306_monitor_stream_keyed T
--        INNER JOIN  2306_apache_filtered_keyed L
--        ON L.KSQL_COL_0=T.KSQL_COL_0 EMIT CHANGES; 

/* CREATE TABLE FROM MySQL STREAM  */

CREATE TABLE IF NOT EXISTS 2306_filtered_keyed_table
WITH (KAFKA_TOPIC='adw.2306.filtered.keyed.table', KEY_FORMAT='PROTOBUF', VALUE_FORMAT='AVRO')
AS
SELECT KSQL_COL_0 AS `KEY`, COUNT(*) AS N
FROM 2306_apache_filtered_keyed
GROUP BY KSQL_COL_0;


-- CREATE STREAM IF NOT EXISTS 2306_apache_geoip
--   WITH (KAFKA_TOPIC='adw.2306.geoip')
-- AS SELECT 
--   afk.geoip->ip AS ip,
--   afk.geoip->`as`->organization->name AS nomorg,
--   afk.geoip->`as`->number AS numorg,
--   afk.geoip->geo->postal_code AS postal_code,
--   afk.geoip->geo->city_name AS city_name,
--   afk.geoip->geo->country_name AS country_name,
--   afk.geoip->geo->country_iso_code AS country_iso_code,
--   afk.geoip->geo->region_name AS region_name,
--   afk.geoip->geo->region_iso_code AS region_iso_code,
--   afk.geoip->geo->continent_code AS continent_code,
--   afk.geoip->geo->timezone AS timezone,
--   afk.geoip->geo->location->lon AS lon,
--   afk.geoip->geo->location->lat AS lat,
--   fkt.`KEY` as `KEY`,
--   fkt.N as ipc
-- FROM 2306_apache_filtered_keyed afk INNER JOIN 2306_filtered_keyed_table fkt ON afk.KSQL_COL_0=fkt.KEY;



CREATE TABLE IF NOT EXISTS 2306_apache_geoip
  WITH (KAFKA_TOPIC='adw.2306.geoip')
AS SELECT
  geoip,
  geoip->ip AS ip,
  geoip->`as`->organization->name AS nomorg,
  geoip->`as`->number AS numorg,
  geoip->geo->postal_code AS postal_code,
  geoip->geo->city_name AS city_name,
  geoip->geo->country_name AS country_name,
  geoip->geo->country_iso_code AS country_iso_code,
  geoip->geo->region_name AS region_name,
  geoip->geo->region_iso_code AS region_iso_code,
  geoip->geo->continent_code AS continent_code,
  geoip->geo->timezone AS timezone,
  geoip->geo->location->lon AS lon,
  geoip->geo->location->lat AS lat,
  COUNT(*) as ipc
FROM 2306_apache_filtered_keyed
GROUP BY geoip;

/* Create SINK Connector. pk.mode is record_value (we take a value from a record, IP, to be PK of each value) */
CREATE SINK CONNECTOR IF NOT EXISTS `2306-geoip-jdbc-sink` WITH(
    "connector.class" = 'io.confluent.connect.jdbc.JdbcSinkConnector',
    "connection.url" = 'jdbc:mysql://mysql:3306/kafka',
    "topics" = 'adw.2306.geoip',
    "table.name.format" = 'geoip',
    "key.converter" = 'io.confluent.connect.protobuf.ProtobufConverter',
    "key.converter.schema.registry.url" = 'http://schema-registry:8081',
    "key.converter.schemas.enable" = 'true',
    "value.converter" = 'io.confluent.connect.avro.AvroConverter',
    "value.converter.schema.registry.url" = 'http://schema-registry:8081',
    "value.converter.schemas.enable" = 'true',
    "connection.user" = 'kafka',
    "connection.password" = 'kpwd23',
    "auto.create" = 'false',
    "pk.mode" = 'record_value',
    "pk.fields" = 'IP',
    "insert.mode" = 'upsert',
    "delete.enabled" = 'false',
    "tasks.max" = '1');

/*
CREATE TABLE IF NOT EXISTS 2306_apache_geoip_table
  WITH (KAFKA_TOPIC='adw.2306.geoip_table', VALUE_FORMAT='AVRO')
AS SELECT 
  geoip->ip AS ip,
  COUNT(*) AS request_count
FROM 2306_apache_filtered
GROUP BY geoip->ip;
*/

/* QUERIES */

/* Q1 */

SELECT MSK.KSQL_COL_0 as KEY,MSK.NV, COUNT(*) as N 
FROM 2306_monitor_stream_keyed MSK
INNER JOIN 2306_APACHE_FILTERED_KEYED AFK
WITHIN 1 hour
ON AFK.KSQL_COL_0=MSK.KSQL_COL_0
GROUP BY MSK.KSQL_COL_0, NV
EMIT CHANGES limit 2;

/* Q2 */

SELECT MSK.KSQL_COL_0 as KEY, COLLECT_SET(AFK.HTTP->RESPONSE->STATUS_CODE) as STC, COLLECT_SET(AFK.HTTP->REQUEST->METHOD) as METHODS, MSK.UV, COUNT(*) as N 
FROM 2306_monitor_stream_keyed MSK
INNER JOIN 2306_APACHE_FILTERED_KEYED AFK
WITHIN 1 hour
ON AFK.KSQL_COL_0=MSK.KSQL_COL_0
GROUP BY MSK.KSQL_COL_0, MSK.UV
EMIT CHANGES limit 100;
